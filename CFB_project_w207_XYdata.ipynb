{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"gamesXY2007-2019.csv\")\n",
    "\n",
    "train_labels = df[df.season < 2015][\"home_win\"]\n",
    "test_labels = df[df.season > 2014][\"home_win\"]\n",
    "\n",
    "df_modeling = df[['h_avg_score_spread', 'h_n_games', 'h_avg_wins', 'h_avg_home_games',\n",
    "       'h_avg_home_wins', 'h_avg_first_downs', 'h_avg_o_first_downs',\n",
    "       'h_avg_third_down_complete', 'h_avg_o_third_down_complete',\n",
    "       'h_avg_third_down_attempts', 'h_avg_o_third_down_attempts',\n",
    "       'h_avg_total_yards', 'h_avg_o_total_yards', 'h_avg_passing_yards',\n",
    "       'h_avg_o_passing_yards', 'h_avg_passing_complete',\n",
    "       'h_avg_o_passing_complete', 'h_avg_passing_attempts',\n",
    "       'h_avg_o_passing_attempts', 'h_avg_rushing_yards',\n",
    "       'h_avg_o_rushing_yards', 'h_avg_rushing_attempts',\n",
    "       'h_avg_o_rushing_attempts', 'h_avg_penalty_yards',\n",
    "       'h_avg_o_penalty_yards', 'h_avg_turnovers', 'h_avg_o_turnovers',\n",
    "       'h_avg_time_possession', 'h_avg_o_time_possession',\n",
    "       'h_StrengthOfSchedule', 'v_avg_score_spread', 'v_n_games', 'v_avg_wins',\n",
    "       'v_avg_home_games', 'v_avg_home_wins', 'v_avg_first_downs',\n",
    "       'v_avg_o_first_downs', 'v_avg_third_down_complete',\n",
    "       'v_avg_o_third_down_complete', 'v_avg_third_down_attempts',\n",
    "       'v_avg_o_third_down_attempts', 'v_avg_total_yards',\n",
    "       'v_avg_o_total_yards', 'v_avg_passing_yards', 'v_avg_o_passing_yards',\n",
    "       'v_avg_passing_complete', 'v_avg_o_passing_complete',\n",
    "       'v_avg_passing_attempts', 'v_avg_o_passing_attempts',\n",
    "       'v_avg_rushing_yards', 'v_avg_o_rushing_yards',\n",
    "       'v_avg_rushing_attempts', 'v_avg_o_rushing_attempts',\n",
    "       'v_avg_penalty_yards', 'v_avg_o_penalty_yards', 'v_avg_turnovers',\n",
    "       'v_avg_o_turnovers', 'v_avg_time_possession', 'v_avg_o_time_possession',\n",
    "       'v_StrengthOfSchedule', 'game_id',\n",
    "       'home_id', 'visitor_id', 'season', 'neutralSite']]\n",
    "\n",
    "train_data = df_modeling[df_modeling.season < 2015]\n",
    "test_data = df_modeling[df_modeling.season > 2014]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['h_avg_score_spread', 'h_n_games', 'h_avg_wins', 'h_avg_home_games',\n",
       "       'h_avg_home_wins', 'h_avg_first_downs', 'h_avg_o_first_downs',\n",
       "       'h_avg_third_down_complete', 'h_avg_o_third_down_complete',\n",
       "       'h_avg_third_down_attempts', 'h_avg_o_third_down_attempts',\n",
       "       'h_avg_total_yards', 'h_avg_o_total_yards', 'h_avg_passing_yards',\n",
       "       'h_avg_o_passing_yards', 'h_avg_passing_complete',\n",
       "       'h_avg_o_passing_complete', 'h_avg_passing_attempts',\n",
       "       'h_avg_o_passing_attempts', 'h_avg_rushing_yards',\n",
       "       'h_avg_o_rushing_yards', 'h_avg_rushing_attempts',\n",
       "       'h_avg_o_rushing_attempts', 'h_avg_penalty_yards',\n",
       "       'h_avg_o_penalty_yards', 'h_avg_turnovers', 'h_avg_o_turnovers',\n",
       "       'h_avg_time_possession', 'h_avg_o_time_possession',\n",
       "       'h_StrengthOfSchedule', 'v_avg_score_spread', 'v_n_games', 'v_avg_wins',\n",
       "       'v_avg_home_games', 'v_avg_home_wins', 'v_avg_first_downs',\n",
       "       'v_avg_o_first_downs', 'v_avg_third_down_complete',\n",
       "       'v_avg_o_third_down_complete', 'v_avg_third_down_attempts',\n",
       "       'v_avg_o_third_down_attempts', 'v_avg_total_yards',\n",
       "       'v_avg_o_total_yards', 'v_avg_passing_yards', 'v_avg_o_passing_yards',\n",
       "       'v_avg_passing_complete', 'v_avg_o_passing_complete',\n",
       "       'v_avg_passing_attempts', 'v_avg_o_passing_attempts',\n",
       "       'v_avg_rushing_yards', 'v_avg_o_rushing_yards',\n",
       "       'v_avg_rushing_attempts', 'v_avg_o_rushing_attempts',\n",
       "       'v_avg_penalty_yards', 'v_avg_o_penalty_yards', 'v_avg_turnovers',\n",
       "       'v_avg_o_turnovers', 'v_avg_time_possession', 'v_avg_o_time_possession',\n",
       "       'v_StrengthOfSchedule', 'game_id', 'home_id', 'visitor_id', 'season',\n",
       "       'neutralSite'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_train_data = scaler.fit_transform(train_data)\n",
    "scaled_test_data = scaler.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes model works with 66.6% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unscaled\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6653    0.4448    0.5331      1077\n",
      "           1     0.6661    0.8319    0.7398      1434\n",
      "\n",
      "    accuracy                         0.6659      2511\n",
      "   macro avg     0.6657    0.6383    0.6365      2511\n",
      "weighted avg     0.6658    0.6659    0.6512      2511\n",
      "\n",
      "Scaled\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6205    0.2080    0.3115      1077\n",
      "           1     0.6033    0.9045    0.7238      1434\n",
      "\n",
      "    accuracy                         0.6057      2511\n",
      "   macro avg     0.6119    0.5562    0.5177      2511\n",
      "weighted avg     0.6107    0.6057    0.5470      2511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(train_data, train_labels)\n",
    "accuracy_nb = np.mean(nb.predict(test_data) == test_labels)\n",
    "\n",
    "print(\"Unscaled\")\n",
    "print(classification_report(test_labels,nb.predict(test_data), digits = 4))\n",
    "\n",
    "nb = BernoulliNB()\n",
    "nb.fit(scaled_train_data, train_labels)\n",
    "accuracy_nb = np.mean(nb.predict(scaled_test_data) == test_labels)\n",
    "\n",
    "print(\"Scaled\")\n",
    "print(classification_report(test_labels,nb.predict(scaled_test_data), digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.6658701712465154\n",
      "0.1 0.6658701712465154\n",
      "1 0.6658701712465154\n",
      "5 0.6658701712465154\n",
      "10 0.666268418956591\n",
      "50 0.6690561529271206\n",
      "100 0.6133014735165273\n"
     ]
    }
   ],
   "source": [
    "for a in [0.01, 0.1, 1, 5, 10, 50, 100]:\n",
    "    nb = BernoulliNB(alpha = a)\n",
    "    nb.fit(train_data, train_labels)\n",
    "    accuracy_nb = np.mean(nb.predict(test_data) == test_labels)\n",
    "    print(a, accuracy_nb)\n",
    "# Best alpha seems to be 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Naive Bayes so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6690561529271206\n"
     ]
    }
   ],
   "source": [
    "best_nb = BernoulliNB(alpha = 50, fit_prior = True)\n",
    "best_nb.fit(train_data, train_labels)\n",
    "accuracy_best_nb = np.mean(best_nb.predict(test_data) == test_labels)\n",
    "print(accuracy_best_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-98-4e80797185f4>, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-98-4e80797185f4>\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    for c in [0.001, 0.01, 0.1, 1 10, 100]:\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "max_acc = 0\n",
    "optimal_c = 0\n",
    "all_accuracies = []\n",
    "\n",
    "for c in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    svm = SVC(C = c, gamma = \"auto\")\n",
    "    svm.fit(train_data, train_labels)\n",
    "    accuracy_svm = np.mean(svm.predict(test_data) == test_labels)\n",
    "    all_accuracies.append(accuracy_svm)\n",
    "\n",
    "    #print(classification_report(test_labels,svm.predict(test_data), digits = 4))\n",
    "    if accuracy_svm > max_acc:\n",
    "        max_acc = accuracy_svm\n",
    "        optimal_c = c\n",
    "        \n",
    "print(\"Unscaled\")\n",
    "print(\"Optimal C Value:\", optimal_c)\n",
    "print(\"Accuracy: \", max_acc)\n",
    "print(all_accuracies)\n",
    "\n",
    "max_acc = 0\n",
    "optimal_c = 0\n",
    "all_accuracies = []\n",
    "\n",
    "for c in [0.001, 0.01, 0.1, 1 10, 100]:\n",
    "    svm = SVC(C = c, gamma = \"auto\")\n",
    "    svm.fit(scaled_train_data, train_labels)\n",
    "    accuracy_svm = np.mean(svm.predict(scaled_test_data) == test_labels)\n",
    "    all_accuracies.append(accuracy_svm)\n",
    "\n",
    "    #print(classification_report(test_labels,svm.predict(test_data), digits = 4))\n",
    "    if accuracy_svm > max_acc:\n",
    "        max_acc = accuracy_svm\n",
    "        optimal_c = c\n",
    "        \n",
    "print(\"\\nScaled\")\n",
    "print(\"Optimal C Value:\", optimal_c)\n",
    "print(\"Accuracy: \", max_acc)\n",
    "print(all_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaled\n",
      "Optimal C Value: 1\n",
      "Accuracy:  0.6977299880525687\n",
      "[0.5710872162485066, 0.5890083632019116, 0.694942254082039, 0.6977299880525687, 0.6730386300278773, 0.6559139784946236]\n"
     ]
    }
   ],
   "source": [
    "#unscaled is just worse across the board for SVM\n",
    "\n",
    "'''max_acc = 0\n",
    "optimal_c = 0\n",
    "all_accuracies = []\n",
    "for c in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    svm = SVC(C = c, gamma = \"scale\")\n",
    "    svm.fit(train_data, train_labels)\n",
    "    accuracy_svm = np.mean(svm.predict(test_data) == test_labels)\n",
    "    all_accuracies.append(accuracy_svm)\n",
    "\n",
    "    #print(classification_report(test_labels,svm.predict(test_data), digits = 4))\n",
    "    if accuracy_svm > max_acc:\n",
    "        max_acc = accuracy_svm\n",
    "        optimal_c = c\n",
    "    \n",
    "print(\"Unscaled\")\n",
    "print(\"Optimal C Value:\", optimal_c)\n",
    "print(\"Accuracy: \", max_acc)\n",
    "print(all_accuracies)'''\n",
    "\n",
    "max_acc = 0\n",
    "optimal_c = 0\n",
    "all_accuracies = []\n",
    "\n",
    "for c in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    svm = SVC(C = c, gamma = \"scale\")\n",
    "    svm.fit(scaled_train_data, train_labels)\n",
    "    accuracy_svm = np.mean(svm.predict(scaled_test_data) == test_labels)\n",
    "    all_accuracies.append(accuracy_svm)\n",
    "\n",
    "    #print(classification_report(test_labels,svm.predict(test_data), digits = 4))\n",
    "    if accuracy_svm > max_acc:\n",
    "        max_acc = accuracy_svm\n",
    "        optimal_c = c\n",
    "        \n",
    "print(\"\\nScaled\")\n",
    "print(\"Optimal C Value:\", optimal_c)\n",
    "print(\"Accuracy: \", max_acc)\n",
    "print(all_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaled\n",
      "Optimal C Value: 0.8\n",
      "Accuracy:  0.7076861808044603\n",
      "[0.7025089605734767, 0.7041019514137794, 0.7076861808044603, 0.7052966945440063, 0.7045001991238551, 0.7064914376742334, 0.7068896853843091]\n"
     ]
    }
   ],
   "source": [
    "max_acc = 0\n",
    "optimal_c = 0\n",
    "all_accuracies = []\n",
    "\n",
    "for c in [0.6, 0.7, 0.8, 0.9, 1, 2, 3]:\n",
    "    svm = SVC(C = c, gamma = \"auto\")\n",
    "    svm.fit(scaled_train_data, train_labels)\n",
    "    accuracy_svm = np.mean(svm.predict(scaled_test_data) == test_labels)\n",
    "    all_accuracies.append(accuracy_svm)\n",
    "\n",
    "    #print(classification_report(test_labels,svm.predict(test_data), digits = 4))\n",
    "    if accuracy_svm > max_acc:\n",
    "        max_acc = accuracy_svm\n",
    "        optimal_c = c\n",
    "        \n",
    "print(\"\\nScaled\")\n",
    "print(\"Optimal C Value:\", optimal_c)\n",
    "print(\"Accuracy: \", max_acc)\n",
    "print(all_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best SVM so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7076861808044603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6974    0.5627    0.6228      1077\n",
      "           1     0.7132    0.8166    0.7614      1434\n",
      "\n",
      "    accuracy                         0.7077      2511\n",
      "   macro avg     0.7053    0.6896    0.6921      2511\n",
      "weighted avg     0.7064    0.7077    0.7019      2511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_svm = SVC(C = 0.8, gamma = \"auto\")\n",
    "best_svm.fit(scaled_train_data, train_labels)\n",
    "accuracy_best_svm = np.mean(best_svm.predict(scaled_test_data) == test_labels)\n",
    "print(accuracy_best_svm)\n",
    "print(classification_report(test_labels,best_svm.predict(scaled_test_data), digits = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrybazakas/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8000    0.3491    0.4861      1077\n",
      "           1     0.6565    0.9344    0.7712      1434\n",
      "\n",
      "    accuracy                         0.6834      2511\n",
      "   macro avg     0.7283    0.6418    0.6287      2511\n",
      "weighted avg     0.7181    0.6834    0.6489      2511\n",
      "\n",
      "\n",
      "L2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7429    0.4345    0.5483      1077\n",
      "           1     0.6762    0.8870    0.7674      1434\n",
      "\n",
      "    accuracy                         0.6930      2511\n",
      "   macro avg     0.7095    0.6608    0.6579      2511\n",
      "weighted avg     0.7048    0.6930    0.6735      2511\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrybazakas/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#worse\n",
    "'''log_reg = LogisticRegression()\n",
    "log_reg.fit(train_data, train_labels)\n",
    "accuracy_log_reg = np.mean(log_reg.predict(test_data) == test_labels)\n",
    "print(accuracy_log_reg)\n",
    "print(classification_report(test_labels,log_reg.predict(test_data), digits = 4))'''\n",
    "\n",
    "# L1 vs L2 \n",
    "\n",
    "log_reg = LogisticRegression(\"l1\")\n",
    "log_reg.fit(scaled_train_data, train_labels)\n",
    "accuracy_log_reg = np.mean(log_reg.predict(scaled_test_data) == test_labels)\n",
    "print(\"L1\")\n",
    "print(classification_report(test_labels,log_reg.predict(scaled_test_data), digits = 4))\n",
    "\n",
    "log_reg = LogisticRegression(\"l2\")\n",
    "log_reg.fit(scaled_train_data, train_labels)\n",
    "accuracy_log_reg = np.mean(log_reg.predict(scaled_test_data) == test_labels)\n",
    "print(\"\\nL2\")\n",
    "print(classification_report(test_labels,log_reg.predict(scaled_test_data), digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrybazakas/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/henrybazakas/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/henrybazakas/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/henrybazakas/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2, C =  0.005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6961    0.4763    0.5656      1077\n",
      "           1     0.6821    0.8438    0.7544      1434\n",
      "\n",
      "    accuracy                         0.6862      2511\n",
      "   macro avg     0.6891    0.6601    0.6600      2511\n",
      "weighted avg     0.6881    0.6862    0.6734      2511\n",
      "\n",
      "L2, C =  0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6947    0.5682    0.6251      1077\n",
      "           1     0.7147    0.8124    0.7604      1434\n",
      "\n",
      "    accuracy                         0.7077      2511\n",
      "   macro avg     0.7047    0.6903    0.6928      2511\n",
      "weighted avg     0.7061    0.7077    0.7024      2511\n",
      "\n",
      "L2, C =  0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7213    0.4903    0.5837      1077\n",
      "           1     0.6914    0.8577    0.7656      1434\n",
      "\n",
      "    accuracy                         0.7001      2511\n",
      "   macro avg     0.7064    0.6740    0.6747      2511\n",
      "weighted avg     0.7042    0.7001    0.6876      2511\n",
      "\n",
      "L2, C =  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7429    0.4345    0.5483      1077\n",
      "           1     0.6762    0.8870    0.7674      1434\n",
      "\n",
      "    accuracy                         0.6930      2511\n",
      "   macro avg     0.7095    0.6608    0.6579      2511\n",
      "weighted avg     0.7048    0.6930    0.6735      2511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in [0.005, 0.1, 0.5, 1]:\n",
    "    log_reg = LogisticRegression(\"l2\", C = c)\n",
    "    log_reg.fit(scaled_train_data, train_labels)\n",
    "    accuracy_log_reg = np.mean(log_reg.predict(scaled_test_data) == test_labels)\n",
    "    print(\"L2, C = \", c)\n",
    "    print(classification_report(test_labels,log_reg.predict(scaled_test_data), digits = 4))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Logistic Regression so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrybazakas/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7076861808044603"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_log_reg = LogisticRegression(\"l2\", C = 0.1)\n",
    "best_log_reg.fit(scaled_train_data, train_labels)\n",
    "accuracy_best_log_reg = np.mean(best_log_reg.predict(scaled_test_data) == test_labels)\n",
    "accuracy_best_log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7084826762246117"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_predictions = best_svm.predict(scaled_test_data) + best_log_reg.predict(scaled_test_data) + best_nb.predict(test_data)\n",
    "prediction_voted = sum_predictions > 1.5\n",
    "combined_accuracy = np.mean(prediction_voted == test_labels)\n",
    "combined_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "updated with optimal values from below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrybazakas/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic Regression. L2, C =  0.1\n",
      "0.6969334926324173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6653    0.5905    0.6257      1077\n",
      "           1     0.7164    0.7768    0.7454      1434\n",
      "\n",
      "    accuracy                         0.6969      2511\n",
      "   macro avg     0.6908    0.6837    0.6855      2511\n",
      "weighted avg     0.6945    0.6969    0.6940      2511\n",
      "\n",
      "SVM. c = 0.8\n",
      "0.688968538430904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6800    0.5190    0.5887      1077\n",
      "           1     0.6933    0.8166    0.7499      1434\n",
      "\n",
      "    accuracy                         0.6890      2511\n",
      "   macro avg     0.6867    0.6678    0.6693      2511\n",
      "weighted avg     0.6876    0.6890    0.6808      2511\n",
      "\n",
      "Bernoulli NB. alpha = 50\n",
      "0.6814018319394664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6325    0.6137    0.6230      1077\n",
      "           1     0.7162    0.7322    0.7241      1434\n",
      "\n",
      "    accuracy                         0.6814      2511\n",
      "   macro avg     0.6744    0.6730    0.6736      2511\n",
      "weighted avg     0.6803    0.6814    0.6808      2511\n",
      "\n",
      "PCA ensemble: 0.6965352449223416\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=25, whiten=True)\n",
    "pca_train = pca.fit_transform(scaled_train_data)\n",
    "pca_test = pca.transform(scaled_test_data)\n",
    "\n",
    "log_reg_pca = LogisticRegression(\"l2\", C = 0.1)\n",
    "log_reg_pca.fit(pca_train, train_labels)\n",
    "accuracy_log_reg_pca = np.mean(log_reg_pca.predict(pca_test) == test_labels)\n",
    "print(\"Logisitic Regression. L2, C = \", 0.1)\n",
    "print(accuracy_log_reg_pca)\n",
    "print(classification_report(test_labels,log_reg_pca.predict(pca_test), digits = 4))\n",
    "\n",
    "svm_pca = SVC(C = 0.6, gamma = \"auto\")\n",
    "svm_pca.fit(pca_train, train_labels)\n",
    "accuracy_svm_pca = np.mean(svm_pca.predict(pca_test) == test_labels)\n",
    "print(\"SVM. c = 0.8\")\n",
    "print(accuracy_svm_pca)\n",
    "print(classification_report(test_labels,svm_pca.predict(pca_test), digits = 4))\n",
    "\n",
    "nb_pca = BernoulliNB(alpha = 50, fit_prior = True)\n",
    "nb_pca.fit(pca_train, train_labels)\n",
    "accuracy_nb_pca = np.mean(nb_pca.predict(pca_test) == test_labels)\n",
    "print(\"Bernoulli NB. alpha = 50\")\n",
    "print(accuracy_nb_pca)\n",
    "print(classification_report(test_labels,nb_pca.predict(pca_test), digits = 4))\n",
    "\n",
    "sum_predictions_pca = svm_pca.predict(pca_test) + log_reg_pca.predict(pca_test) + nb_pca.predict(pca_test)\n",
    "prediction_voted_pca = sum_predictions_pca > 1.5\n",
    "combined_accuracy_pca = np.mean(prediction_voted_pca == test_labels)\n",
    "print(\"PCA ensemble:\",combined_accuracy_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Bernoulli NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.6802070888092393\n",
      "0.1 0.6802070888092393\n",
      "1 0.680605336519315\n",
      "5 0.680605336519315\n",
      "10 0.6802070888092393\n",
      "50 0.680605336519315\n",
      "100 0.680605336519315\n",
      "1000 0.678215850258861\n"
     ]
    }
   ],
   "source": [
    "for a in [0.01, 0.1, 1, 5, 10, 50, 100, 1000]:\n",
    "    nb = BernoulliNB(alpha = a)\n",
    "    nb.fit(pca_train, train_labels)\n",
    "    accuracy_nb = np.mean(nb.predict(pca_test) == test_labels)\n",
    "    print(a, accuracy_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6636    0.5989    0.6296      1077\n",
      "           1     0.7193    0.7720    0.7447      1434\n",
      "\n",
      "    accuracy                         0.6977      2511\n",
      "   macro avg     0.6914    0.6854    0.6871      2511\n",
      "weighted avg     0.6954    0.6977    0.6953      2511\n",
      "\n",
      "\n",
      "L2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6643    0.6007    0.6309      1077\n",
      "           1     0.7202    0.7720    0.7452      1434\n",
      "\n",
      "    accuracy                         0.6985      2511\n",
      "   macro avg     0.6923    0.6864    0.6881      2511\n",
      "weighted avg     0.6962    0.6985    0.6962      2511\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrybazakas/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/henrybazakas/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(\"l1\")\n",
    "log_reg.fit(pca_train, train_labels)\n",
    "accuracy_log_reg = np.mean(log_reg.predict(pca_test) == test_labels)\n",
    "print(\"L1\")\n",
    "print(classification_report(test_labels,log_reg.predict(pca_test), digits = 4))\n",
    "\n",
    "log_reg = LogisticRegression(\"l2\")\n",
    "log_reg.fit(pca_train, train_labels)\n",
    "accuracy_log_reg = np.mean(log_reg.predict(pca_test) == test_labels)\n",
    "print(\"\\nL2\")\n",
    "print(classification_report(test_labels,log_reg.predict(pca_test), digits = 4))\n",
    "\n",
    "# very similar. L2 appears slightly better I guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2, C =  0.005 0.678215850258861\n",
      "L2, C =  0.1 0.7001194743130227\n",
      "L2, C =  0.5 0.6981282357626444\n",
      "L2, C =  1 0.6977299880525687\n",
      "L2, C =  10 0.6981282357626444\n",
      "L2, C =  1000 0.6985264834727201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrybazakas/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/henrybazakas/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/henrybazakas/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/henrybazakas/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/henrybazakas/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/henrybazakas/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for c in [0.005, 0.1, 0.5, 1, 10, 1000]:\n",
    "    log_reg = LogisticRegression(\"l1\", C = c)\n",
    "    log_reg.fit(pca_train, train_labels)\n",
    "    accuracy_log_reg = np.mean(log_reg.predict(pca_test) == test_labels)\n",
    "    print(\"L2, C = \", c, accuracy_log_reg)\n",
    "    #print(classification_report(test_labels,log_reg.predict(pca_test), digits = 4))\n",
    "    \n",
    "#0.1 still seems to be the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaled\n",
      "Optimal C Value: 0.1\n",
      "Accuracy:  0.6833930704898447\n",
      "[0.5710872162485066, 0.5710872162485066, 0.6833930704898447, 0.675826363998407, 0.6296296296296297, 0.6232576662684189]\n"
     ]
    }
   ],
   "source": [
    "max_acc = 0\n",
    "optimal_c = 0\n",
    "all_accuracies = []\n",
    "\n",
    "for c in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    svm = SVC(C = c, gamma = \"auto\")\n",
    "    svm.fit(pca_train, train_labels)\n",
    "    accuracy_svm = np.mean(svm.predict(pca_test) == test_labels)\n",
    "    all_accuracies.append(accuracy_svm)\n",
    "\n",
    "    #print(classification_report(test_labels,svm.predict(test_data), digits = 4))\n",
    "    if accuracy_svm > max_acc:\n",
    "        max_acc = accuracy_svm\n",
    "        optimal_c = c\n",
    "        \n",
    "print(\"\\nScaled\")\n",
    "print(\"Optimal C Value:\", optimal_c)\n",
    "print(\"Accuracy: \", max_acc)\n",
    "print(all_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaled\n",
      "Optimal C Value: 0.6\n",
      "Accuracy:  0.6885702907208283\n",
      "[0.6885702907208283, 0.6861808044603743, 0.681800079649542, 0.6810035842293907, 0.675826363998407, 0.672242134607726, 0.665073675826364]\n"
     ]
    }
   ],
   "source": [
    "max_acc = 0\n",
    "optimal_c = 0\n",
    "all_accuracies = []\n",
    "\n",
    "for c in [0.6, 0.7, 0.8, 0.9, 1, 2, 3]:\n",
    "    svm = SVC(C = c, gamma = \"auto\")\n",
    "    svm.fit(pca_train, train_labels)\n",
    "    accuracy_svm = np.mean(svm.predict(pca_test) == test_labels)\n",
    "    all_accuracies.append(accuracy_svm)\n",
    "\n",
    "    #print(classification_report(test_labels,svm.predict(test_data), digits = 4))\n",
    "    if accuracy_svm > max_acc:\n",
    "        max_acc = accuracy_svm\n",
    "        optimal_c = c\n",
    "        \n",
    "print(\"\\nScaled\")\n",
    "print(\"Optimal C Value:\", optimal_c)\n",
    "print(\"Accuracy: \", max_acc)\n",
    "print(all_accuracies)\n",
    "\n",
    "# 0.6 is now the best c value. marginal change\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVERALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 0.7077\n",
      "Logistic Regression PCA 0.6969\n",
      "SVM 0.7077\n",
      "SVM PCA 0.689\n",
      "Bernoulli Naive Bayes 0.679\n",
      "Bernoulli Naive Bayes PCA 0.6814\n"
     ]
    }
   ],
   "source": [
    "accuracies = [accuracy_best_log_reg,\n",
    "accuracy_log_reg_pca,\n",
    "accuracy_best_svm,\n",
    "accuracy_svm_pca,\n",
    "accuracy_best_nb,\n",
    "accuracy_nb_pca]\n",
    "\n",
    "names = [\"Logistic Regression\", \"Logistic Regression PCA\", \"SVM\", \"SVM PCA\", \"Bernoulli Naive Bayes\", \"Bernoulli Naive Bayes PCA\"]\n",
    "\n",
    "for i in range(len(accuracies)):\n",
    "    print(names[i], round(accuracies[i], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracies for various models')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [\"red\",\"red\",\"green\",\"green\",\"blue\",\"blue\"]\n",
    "\n",
    "plt.barh(names, accuracies, color = colors)\n",
    "plt.title(\"Accuracies for various models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Models\n",
    "\n",
    "These are the best models I was able to generate, whose accuracies are displayed in the table above. For all three there is a version trained on PCA data and a version trained on normal data. PCA performed marginally better for Bernoulli Naive Bayes and worse for SVM and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrybazakas/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/henrybazakas/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic Regression. L2, C =  0.1\n",
      "0.7077\n",
      "Logisitic Regression with PCA. L2, C =  0.1\n",
      "0.6969\n",
      "SVM. c = 0.8\n",
      "0.7077\n",
      "SVM with PCA. c = 0.6\n",
      "0.689\n",
      "Bernoulli NB. alpha = 50\n",
      "0.6691\n",
      "Bernoulli NB with PCA. alpha = 50\n",
      "0.6814\n"
     ]
    }
   ],
   "source": [
    "best_log_reg = LogisticRegression(\"l2\", C = 0.1)\n",
    "best_log_reg.fit(scaled_train_data, train_labels)\n",
    "accuracy_best_log_reg = np.mean(best_log_reg.predict(scaled_test_data) == test_labels)\n",
    "print(\"Logisitic Regression. L2, C = \", 0.1)\n",
    "print(round(accuracy_best_log_reg,4))\n",
    "\n",
    "log_reg_pca = LogisticRegression(\"l2\", C = 0.1)\n",
    "log_reg_pca.fit(pca_train, train_labels)\n",
    "accuracy_log_reg_pca = np.mean(log_reg_pca.predict(pca_test) == test_labels)\n",
    "print(\"Logisitic Regression with PCA. L2, C = \", 0.1)\n",
    "print(round(accuracy_log_reg_pca, 4))\n",
    "#print(classification_report(test_labels,log_reg_pca.predict(pca_test), digits = 4))\n",
    "\n",
    "best_svm = SVC(C = 0.8, gamma = \"auto\")\n",
    "best_svm.fit(scaled_train_data, train_labels)\n",
    "accuracy_best_svm = np.mean(best_svm.predict(scaled_test_data) == test_labels)\n",
    "print(\"SVM. c = 0.8\")\n",
    "print(round(accuracy_best_svm, 4))\n",
    "#print(classification_report(test_labels,best_svm.predict(scaled_test_data), digits = 4))\n",
    "\n",
    "svm_pca = SVC(C = 0.6, gamma = \"auto\")\n",
    "svm_pca.fit(pca_train, train_labels)\n",
    "accuracy_svm_pca = np.mean(svm_pca.predict(pca_test) == test_labels)\n",
    "print(\"SVM with PCA. c = 0.6\")\n",
    "print(round(accuracy_svm_pca, 4))\n",
    "#print(classification_report(test_labels,svm_pca.predict(pca_test), digits = 4))\n",
    "\n",
    "best_nb = BernoulliNB(alpha = 50, fit_prior = True)\n",
    "best_nb.fit(train_data, train_labels)\n",
    "accuracy_best_nb = np.mean(best_nb.predict(test_data) == test_labels)\n",
    "print(\"Bernoulli NB. alpha = 50\")\n",
    "print(round(accuracy_best_nb, 4))\n",
    "\n",
    "nb_pca = BernoulliNB(alpha = 50, fit_prior = True)\n",
    "nb_pca.fit(pca_train, train_labels)\n",
    "accuracy_nb_pca = np.mean(nb_pca.predict(pca_test) == test_labels)\n",
    "print(\"Bernoulli NB with PCA. alpha = 50\")\n",
    "print(round(accuracy_nb_pca, 4))\n",
    "#print(classification_report(test_labels,nb_pca.predict(pca_test), digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
